{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from diro2c.data_generation.helper import *\n",
    "import minisom\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from diro2c.data_generation.neighborhood_generation import modified_gpdatagenerator\n",
    "from diro2c.data_generation.distance_functions import simple_match_distance, normalized_euclidean_distance, mixed_distance\n",
    "from diro2c.data_generation.helper import *\n",
    "from diro2c.enums.diff_classifier_method_type import diff_classifier_method_type\n",
    "from diro2c.data_generation.neighborhood_generation.gpdatagenerator import calculate_feature_values\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "from collections import defaultdict\n",
    "from scipy.cluster.hierarchy import dendrogram, set_link_color_palette\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.pylab as pl\n",
    "from data.getdata import loaddata, prepare_df\n",
    "from data.split3fold import split3fold\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "from vars import plot_colors, color_dict, classes_dict\n",
    "\n",
    "from sklearn.tree import plot_tree\n",
    "import re\n",
    "import matplotlib\n",
    "def replace_text(obj):\n",
    "    if type(obj) == matplotlib.text.Annotation:\n",
    "        txt = obj.get_text()\n",
    "        txt = re.sub(\"samples[^$]*class\",\"class\",txt)\n",
    "        obj.set_text(txt)\n",
    "    return obj"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def getclusterid(x, som, clusterarr):\n",
    "    #x ... normalized instance\n",
    "    bmu = getwinnerid(x, som)\n",
    "    c = clusterarr.loc[clusterarr.node == bmu, 'cluster']\n",
    "    return c\n",
    "\n",
    "def getwinnerid(x, som):\n",
    "    #x ... normalized instance\n",
    "    bmu = som.winner(x)[1]\n",
    "    return bmu\n",
    "\n",
    "def distance_function(x0, x1, discrete, continuous, class_name):\n",
    "    return mixed_distance(x0, x1, discrete, continuous, class_name,\n",
    "                          ddist=simple_match_distance,\n",
    "                          cdist=normalized_euclidean_distance)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = 'compas'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataA, dataB, cols, discrete, continuous, le = loaddata(data)\n",
    "blackboxtrainA, trainA, testA = split3fold(dataA, 0.4, 0.2, random_state=1)\n",
    "blackboxtrainB, trainB, testB = split3fold(dataB, 0.4, 0.2, random_state=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "modelA = pickle.load(open('blackboxes/'+data+'A.sav', 'rb'))\n",
    "modelB = pickle.load(open('blackboxes/'+data+'B.sav', 'rb'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train = pd.concat([trainA, trainB])\n",
    "train['predA'] = modelA.predict(train[cols].values)\n",
    "train['predB'] = modelB.predict(train[cols].values)\n",
    "train['difference'] = train.apply(lambda row: str(int(row['predA'])) + '|' + str(int(row['predB'])), axis = 1)\n",
    "train.drop(columns=['predA', 'predB', 'y'], inplace=True, errors='ignore')\n",
    "train = train.reset_index(drop=True)\n",
    "test = pd.concat([testA, testB])\n",
    "test['predA'] = modelA.predict(test[cols].values)\n",
    "test['predB'] = modelB.predict(test[cols].values)\n",
    "test['difference'] = test.apply(lambda row: str(int(row['predA'])) + '|' + str(int(row['predB'])), axis = 1)\n",
    "test.drop(columns=['predA', 'predB', 'y'], inplace=True)\n",
    "test = test.reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Prepare data:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "discrete_woclassname = discrete.copy()\n",
    "discrete.append('difference')\n",
    "\n",
    "d = defaultdict(lambda: OneHotEncoder(drop = 'first'))\n",
    "trainbinary = train.copy()\n",
    "testbinary = test.copy()\n",
    "colsbinary = cols.copy()\n",
    "\n",
    "for feature in discrete_woclassname:\n",
    "    uniquevals = np.concatenate((trainbinary[feature].values.reshape(-1,1), testbinary[feature].values.reshape(-1,1)))\n",
    "    d[feature].fit(uniquevals)\n",
    "    tmp = d[feature].transform(trainbinary[feature].values.reshape(-1,1)).toarray()\n",
    "    colnames = [feature + str(i) for i in range(tmp.shape[1])]\n",
    "    trainbinary[colnames] = tmp\n",
    "    testbinary[colnames] = d[feature].transform(testbinary[feature].values.reshape(-1,1)).toarray()\n",
    "    colsbinary = colsbinary + colnames\n",
    "    colsbinary.remove(feature)\n",
    "    trainbinary.drop(columns = feature, inplace = True)\n",
    "    testbinary.drop(columns = feature, inplace = True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1-dim SOM to structure dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainsom = trainbinary[colsbinary].values\n",
    "testsom = testbinary[colsbinary].values\n",
    "trainsomnormfull = trainbinary[colsbinary].copy()\n",
    "testsomnorm = testbinary[colsbinary].copy()\n",
    "scaler = StandardScaler()\n",
    "scaler = scaler.fit(trainsomnormfull[continuous].values)\n",
    "trainsomnormfull[continuous] = scaler.transform(trainsomnormfull[continuous].values)\n",
    "testsomnorm[continuous] = scaler.transform(testsomnorm[continuous].values)\n",
    "\n",
    "trainsomnorm = trainsomnormfull[~train.difference.isin(['0|0', '1|1', '2|2'])]\n",
    "trainsom = trainsom[~train.difference.isin(['0|0', '1|1', '2|2'])]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hyperparameter = pd.read_csv('results/SOMhyperparameterperformance2022-10-17.txt', sep=' ')\n",
    "hyperparameter = hyperparameter.loc[hyperparameter.data == data]\n",
    "hyperparameter = hyperparameter.groupby(['sigma', 'learningrate']).agg('mean').reset_index()\n",
    "print(hyperparameter.loc[hyperparameter.quantization == np.min(hyperparameter.quantization)])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_nodes = int(np.floor(5*np.sqrt(len(trainsom))))\n",
    "som = minisom.MiniSom(1, n_nodes, trainsomnorm.shape[1], sigma=0.9, learning_rate=1.0, random_seed = 0)\n",
    "som.train(trainsomnorm.values, 100000, verbose = True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open('Approach2SOM_' + data + '.pickle', 'wb') as handle:\n",
    "    pickle.dump(som, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Clustering using hierarchical clustering with Ward's linkage criterion"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "connectivity_matrix = np.zeros((n_nodes, n_nodes))\n",
    "for i in range(n_nodes - 1):\n",
    "    connectivity_matrix[i, i + 1] = 1.0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_dendrogram(model, **kwargs):\n",
    "    #copied from official documentation: https://scikit-learn.org/stable/auto_examples/cluster/plot_agglomerative_dendrogram.html\n",
    "    # Create linkage matrix and then plot the dendrogram\n",
    "\n",
    "    # create the counts of samples under each node\n",
    "    counts = np.zeros(model.children_.shape[0])\n",
    "    n_samples = len(model.labels_)\n",
    "    for i, merge in enumerate(model.children_):\n",
    "        current_count = 0\n",
    "        for child_idx in merge:\n",
    "            if child_idx < n_samples:\n",
    "                current_count += 1  # leaf node\n",
    "            else:\n",
    "                current_count += counts[child_idx - n_samples]\n",
    "        counts[i] = current_count\n",
    "\n",
    "    linkage_matrix = np.column_stack(\n",
    "        [model.children_, model.distances_, counts]\n",
    "    ).astype(float)\n",
    "    # Plot the corresponding dendrogram\n",
    "    d = dendrogram(linkage_matrix, **kwargs)\n",
    "    return d"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "weights = som.get_weights()[0]\n",
    "model = AgglomerativeClustering(distance_threshold=0, n_clusters=None,\n",
    "                                connectivity=connectivity_matrix, linkage='single')\n",
    "model = model.fit(weights)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "distance_threshold = {\n",
    "    'compas': 3,\n",
    "    'bankmarketing': 4.5\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "set_link_color_palette(plot_colors)\n",
    "den = plot_dendrogram(model, no_labels=True, color_threshold=distance_threshold[data],\n",
    "                above_threshold_color='k'\n",
    "                )\n",
    "ax.axhline(y=distance_threshold[data], c = 'black', linestyle = 'dotted')\n",
    "ax.set_facecolor('#FFFFFF')\n",
    "plt.savefig('docout/sections/localtoglobal/results/approach4_Dendrogram_SOMNodes_' + data + '.jpg',dpi=300, bbox_inches='tight', transparent=True, pad_inches=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ward = AgglomerativeClustering(connectivity=connectivity_matrix, linkage=\"single\",\n",
    "                               distance_threshold=distance_threshold[data], n_clusters=None).fit(weights)\n",
    "label = ward.labels_\n",
    "clusterarr = pd.DataFrame({'node': range(n_nodes), 'cluster': label})\n",
    "clusterarr['cluster'] = pd.factorize(clusterarr.cluster)[0]\n",
    "ncluster = len(np.unique(label))\n",
    "print(ncluster)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#determine cluster ID for each instance of the training set:\n",
    "clusterwinnerspos = np.apply_along_axis(getclusterid, 1, weights, som, clusterarr)\n",
    "clusterwinners = np.apply_along_axis(getclusterid, 1, trainsomnorm, som, clusterarr)\n",
    "nodeswinners = np.apply_along_axis(getwinnerid, 1, trainsomnorm, som)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "clusterdendrogram = [clusterwinnerspos[x, 0] for x in den['leaves']]\n",
    "clustercolor = [[x, y] for x, y in zip(clusterdendrogram, den['leaves_color_list'])]\n",
    "clustercolor = np.unique(clustercolor, axis=0)\n",
    "clustercolor = clustercolor[clustercolor[:, 0].astype(int).argsort()]\n",
    "alreadyused = clustercolor[~(clustercolor[:, 1] == 'k'), 1]\n",
    "available = [x for x in plot_colors if x not in alreadyused]\n",
    "clustercolor[clustercolor[:, 1] == 'k', 1] = available[:(ncluster - len(alreadyused))]\n",
    "clustercolor = pd.DataFrame(clustercolor, columns=['cluster', 'color'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "clusterswithoutdata = [x for x in range(ncluster) if x not in list(np.unique(clusterwinners))]\n",
    "nodesofclusterwithoutdata = clusterarr.loc[clusterarr.cluster.isin(clusterswithoutdata), 'node'].tolist()\n",
    "#for each cluster, for each node determine nearest node in cluster with data:\n",
    "for node in nodesofclusterwithoutdata:\n",
    "    weightnode = weights[node]\n",
    "    nextnode = node\n",
    "    i = 1\n",
    "    while nextnode in nodesofclusterwithoutdata:\n",
    "        map = som._activation_distance(weightnode, som._weights)[0, [node - i, node + i]].argsort()\n",
    "        nextnode = node + i if map[0] > 0 else node - i\n",
    "        i = i + 1\n",
    "    if nextnode >= n_nodes:\n",
    "        nextnode = node - i\n",
    "    elif nextnode <0:\n",
    "        nextnode = node + i\n",
    "    oldcluster = clusterarr.loc[clusterarr.node == node, 'cluster'].item()\n",
    "    newcluster = clusterarr.loc[clusterarr.node == nextnode, 'cluster'].item()\n",
    "    clusterarr.loc[clusterarr.node == node, 'cluster'] = newcluster\n",
    "    clustercolor.loc[clustercolor.cluster == str(oldcluster), 'color'] = clustercolor.loc[\n",
    "        clustercolor.cluster == str(newcluster), 'color'].item()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#determine cluster ID for each instance of the training set:\n",
    "clusterwinnerspos = np.apply_along_axis(getclusterid, 1, weights, som, clusterarr)\n",
    "clusterwinners = np.apply_along_axis(getclusterid, 1, trainsomnorm, som, clusterarr)\n",
    "nodeswinners = np.apply_along_axis(getwinnerid, 1, trainsomnorm, som)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open('Approach2Clusterarray_' + data + '.pickle', 'wb') as handle:\n",
    "    pickle.dump(clusterarr, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Local Explanations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#build a tree (explainer) for each node:\n",
    "#prep for diroc\n",
    "train['difference'] = train['difference'].astype(str)\n",
    "dataset = prepare_df(train, 'train', 'difference', discrete=discrete, continuous=continuous)\n",
    "features = dataset['columns'].copy()\n",
    "features.remove('difference')\n",
    "X = np.array(train[features])\n",
    "feature_values = calculate_feature_values(\n",
    "    X, dataset['columns'], 'difference', dataset['discrete'], dataset['continuous'], len(train)\n",
    ")\n",
    "discrete_no_class = list(dataset['discrete'])\n",
    "discrete_no_class.remove('difference')\n",
    "\n",
    "neighborhoods = dict()\n",
    "explainers = dict.fromkeys(list(range(ncluster)))\n",
    "\n",
    "clusterassignment = clusterwinners.flatten()\n",
    "\n",
    "traindifferences = train.loc[~train.difference.isin(['0|0', '1|1', '2|2'])]\n",
    "\n",
    "indexinstances = []\n",
    "nodeswithoutdata = [x for x in range(n_nodes) if x not in list(np.unique(nodeswinners))]\n",
    "subclusterarr = clusterarr.loc[~clusterarr.node.isin(nodeswithoutdata)]\n",
    "\n",
    "for clusterid in np.unique(clusterassignment):\n",
    "    print('processing cluster ' + str(clusterid))\n",
    "    if len(subclusterarr.loc[subclusterarr.cluster==clusterid])>4:\n",
    "        start = subclusterarr.loc[subclusterarr.cluster == clusterid,'node'].min()\n",
    "        end = subclusterarr.loc[subclusterarr.cluster == clusterid,'node'].max()\n",
    "        middle = int(subclusterarr.loc[subclusterarr.cluster == clusterid,'node'].median())\n",
    "        nodes = [start, end, middle]\n",
    "    elif len(subclusterarr.loc[subclusterarr.cluster==clusterid])>2:\n",
    "        start = subclusterarr.loc[subclusterarr.cluster == clusterid,'node'].min()\n",
    "        end = subclusterarr.loc[subclusterarr.cluster == clusterid,'node'].max()\n",
    "        nodes = [start, end]\n",
    "    else:\n",
    "        nodes = list(subclusterarr.loc[subclusterarr.cluster == clusterid,'node'].sample(n=1, random_state = 0))\n",
    "\n",
    "    Z3 = np.empty((0, train[cols].shape[1]))\n",
    "\n",
    "    for x in nodes:\n",
    "        indx = (nodeswinners == x)\n",
    "        if indx.sum() >0:\n",
    "            instance = traindifferences.loc[indx].sample(n=1, random_state=0)\n",
    "            instanceindex = instance.index[0]\n",
    "            indexinstances.append(instanceindex)\n",
    "            instance = instance.values.reshape(-1, )[:-1]\n",
    "            Z = modified_gpdatagenerator.generate_modified_data(instance, feature_values, modelA, modelB,\n",
    "                                                                diff_classifier_method_type.multiclass_diff_classifier,\n",
    "                                                                discrete_no_class, dataset['continuous'], 'difference',\n",
    "                                                                dataset['idx_features'],\n",
    "                                                                distance_function, neigtype={'ss': 0.5, 'sd': 0.5},\n",
    "                                                                population_size=1000, halloffame_ratio=None,\n",
    "                                                                alpha1=0.5, alpha2=0.5, eta1=1, eta2=0.0,\n",
    "                                                                tournsize=3, cxpb=0.2, mutpb=0.3, ngen=100,\n",
    "                                                                return_logbook=False, max_steps=10, is_unique=True)\n",
    "            Z3 = np.concatenate([Z3, Z])\n",
    "\n",
    "            #restrict neighborhood to current cluster\n",
    "            Z3df = pd.DataFrame(Z3, columns = cols)\n",
    "            for feature in discrete_no_class:\n",
    "                tmp = d[feature].transform(Z3df[feature].values.reshape(-1,1)).toarray()\n",
    "                colnames = [feature + str(i) for i in range(tmp.shape[1])]\n",
    "                Z3df[colnames] = tmp\n",
    "                Z3df.drop(columns = feature, inplace = True)\n",
    "            Z3df[continuous] = scaler.transform(Z3df[continuous].values)\n",
    "            Z3df = Z3df.values\n",
    "            neighborhoodwinners = np.apply_along_axis(getclusterid, 1, Z3df, som, clusterarr)\n",
    "            ind = (neighborhoodwinners == clusterid).flatten()\n",
    "            Z3 = Z3[ind]\n",
    "\n",
    "    neighborhoods[clusterid] = Z3\n",
    "    predA = modelA.predict(Z3).astype(str)\n",
    "    predB = modelB.predict(Z3).astype(str)\n",
    "    difference = pd.Series(np.char.add(np.char.add(predA, '|'), predB))\n",
    "    clf = DecisionTreeClassifier(random_state=0)\n",
    "    clf.fit(Z3, difference)\n",
    "    explainers[clusterid] = clf\n",
    "    print('finished processing cluster ' + str(clusterid))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open('Approach2Explainer_'+data+'.pickle', 'wb') as handle:\n",
    "    pickle.dump(explainers, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('Approach2Neighborhood_'+data+'.pickle', 'wb') as handle:\n",
    "    pickle.dump(neighborhoods, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open('Approach2Explainer_'+data+'.pickle', 'rb') as handle:\n",
    "    explainers = pickle.load(handle)\n",
    "with open('Approach2Neighborhood_'+data+'.pickle', 'rb') as handle:\n",
    "    neighborhoods = pickle.load(handle)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.sqrt(5 * np.sqrt(len(train)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "shapesom = 30"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#For visualisation:\n",
    "somvis = minisom.MiniSom(shapesom, shapesom, trainsomnormfull.shape[1], sigma=2.0, learning_rate=1.0, random_seed = 0)\n",
    "somvis.train(trainsomnormfull.values, 100000, verbose = True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Z = np.zeros((shapesom, shapesom))\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "clusterassignmentfull = np.apply_along_axis(getclusterid, 1, trainsomnormfull, som, clusterarr).flatten()\n",
    "collector_color = dict.fromkeys(range(ncluster))\n",
    "collector_marker = dict.fromkeys(range(ncluster))\n",
    "\n",
    "#markers = [['o', 'black'], ['v', 'white'], ['^', 'black'],['s', 'black'], ['P', 'black'], ['D', 'white'],['_', 'black'], ['|', 'white'], ['1', 'black'], ['*', 'white']]\n",
    "\n",
    "markers = [['o', 'black'], ['v', 'black'], ['^', 'white'],['s', 'black'], ['P', 'white'], ['D', 'black'],['_', 'black'], ['|', 'black'], ['1', 'black'], ['*', 'white']]\n",
    "\n",
    "w_x, w_y = zip(*[somvis.winner(d) for d in trainsomnormfull.values])\n",
    "for i in np.arange(somvis._weights.shape[0]):\n",
    "    for j in np.arange(somvis._weights.shape[1]):\n",
    "        idx = [x == i and y == j for x,y in zip(w_x, w_y)]\n",
    "        tmp = pd.Series(clusterassignmentfull[idx])\n",
    "        if len(tmp) > 0:\n",
    "            feature = tmp.value_counts().idxmax()\n",
    "            collector_color[feature] = plt.plot([i + .5], [j + .5], marker='s', markersize=15, #22 #15\n",
    "                                                color=clustercolor.loc[clustercolor.cluster == str(feature), 'color'].item(),\n",
    "                                                linewidth = 0)\n",
    "            collector_marker[feature] = plt.plot([i + .5], [j + .5], marker=markers[feature][0],\n",
    "                                                 color=markers[feature][1], markersize=10, #12 #10\n",
    "                                                 markerfacecolor = 'None',linewidth = 0)\n",
    "\n",
    "collector_color = {k: v for k, v in collector_color.items() if v is not None}\n",
    "collector_marker = {k: v for k, v in collector_marker.items() if v is not None}\n",
    "\n",
    "leg = plt.legend([(collector_color[j][0], collector_marker[j][0]) for j in collector_color.keys()],\n",
    "                 [j for j in collector_color.keys()], #markerscale = 0.8,\n",
    "                 title='Cluster', frameon=False, ncol=10, loc='lower left',\n",
    "                 bbox_to_anchor=(0, -0.125)\n",
    "                 )\n",
    "leg._legend_box.align = \"left\"\n",
    "\n",
    "plt.xlim([0, shapesom])\n",
    "plt.ylim([0, shapesom])\n",
    "\n",
    "plt.grid(False)\n",
    "\n",
    "ax.set_xlabel('')\n",
    "ax.set_ylabel('')\n",
    "ax.set_yticklabels([])\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticks([])\n",
    "ax.set_xticks([])\n",
    "\n",
    "plt.savefig('docout/sections/localtoglobal/results/approach4_Regions_SOMprojection_ClassColored_' + data + '.jpg',dpi=150, bbox_inches='tight', transparent=True, pad_inches=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "clusterassignmentfull = np.apply_along_axis(getclusterid, 1, trainsomnormfull, som, clusterarr).flatten()\n",
    "\n",
    "labels_map = somvis.labels_map(trainsomnormfull.values, clusterassignmentfull)\n",
    "the_grid = gridspec.GridSpec(shapesom,shapesom, fig)\n",
    "\n",
    "for position in labels_map.keys():\n",
    "    label_fracs = [labels_map[position][l] for l in clusterassignmentfull]\n",
    "    plt.subplot(the_grid[shapesom-1-position[1],\n",
    "                         position[0]], aspect=1)\n",
    "    patches, texts = plt.pie(label_fracs)\n",
    "\n",
    "plt.savefig('docout/sections/localtoglobal/results/approach4_Regions_SOMprojection_PieClass_' + data + '.jpg',dpi=150, bbox_inches='tight', transparent=True, pad_inches=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "diroc",
   "language": "python",
   "display_name": "diroc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}